\section{概率PCA}
前一节讨论的PCA的形式所基于的是将数据线性投影到比原始数据空间维度更低的子空间内。PCA也可以被视为概率潜在变量模型的最大似然解。PCA的这种形式，被称为概率PCA(probabilistic PCA)，与传统的PCA相比，会带来如下几个优势。
\begin{itemize}
	\item 概率PCA表示高斯分布的一个限制形式，其中自由参数的数量可以受到限制，同时仍然使得模型能够描述数据集的主要的相关关系。
	\item 我们可以为PCA推导一个EM算法，这个算法在只有几个主要的特征向量需要求出的情况下，计算效率比较高，并且避免了计算数据协方差的中间步骤。
	\item 概率模型与EM的结合使得我们能够处理数据集里缺失值的问题。
	\item 概率PCA混合模型可以用一种有理有据的方式进行形式化，并且可以使用EM算法进行训练。
	\item 概率PCA构成了PCA的贝叶斯方法的基础，其中主子空间的维度可以自动从数据中找到。
	\item 似然函数的存在使得直接与其他的概率密度模型进行对比成为可能。相反，传统的PCA会给接近主子空间的数据点分配一个较低的重建代价，即使这些数据点的位置距离训练数据任意远。
	\item 概率PCA可以被用来对类条件概率密度建模，因此可以应用于分类问题。
	\item 概率PCA模型可以用一种生成式的方式运行，从而可以按照某个概率分布生成样本。
\end{itemize}
\subsection*{最大似然PCA}
\subsection*{用于PCA的EM算法}
