\section{贝叶斯模型比较}
前面介绍了使用交叉验证的方法，来设置正则化参数的值，或者从多个模型中选择合适的一个。这里，从贝叶斯的角度考虑模型选择的问题。模型比较的贝叶斯观点仅仅涉及到使用概率来表示模型选择的不确定性，以及恰当地使用概率的加和规则和乘积规则。假设我们想比较L个模型$\{M_i\},i=1,2,\dots,L$。这里，一个模型指的是观测数据D上的概率分布。我们会假设数据是由这些模型中的一个生成的，但是我们不知道究竟是哪一个。我们的不确定性通过先验概率分布$p(M_i)$表示。给定一个数据集D，我们想估计后验分布
\begin{equation}
	p(M_i|D)\propto p(M_i)p(D|M_i)
\end{equation}
先验分布让我们能够表达不同模型之间的优先级。\textbf{我们简单的假设所有的模型都有相同的先验概率}。模型证据(model evidence)$p(D|M_i)$，表达了数据展现出的不同模型的优先级。模型证据有时也被称为边缘似然(marginal likelihood)，因为它可以被看做在模型空间中的似然函数，在这个空间中参数已经被求和或者积分。两个模型的模型证据的比值$\frac{p(D|M_i)}{p(D|M_j)}$被称为贝叶斯因子(Bayes factor)。

一旦我们知道了模型上的后验概率分布，那么根据概率的加和规则与乘积规则，预测分布为
\begin{equation}
	p(t|\boldsymbol{x},D)=\sum_{i=1}^{L}p(t|\boldsymbol{x},M_i,D)p(M_i|D)
\end{equation}
这是混合分布(mixture distribution)的一个例子。这个公式中，整体的预测分布由下面的方式获得：对各个模型的预测分布$p(t|\boldsymbol{x},M_i,D)$求加权平均，权值为这些模型的后验概率$p(M_i|D)$。

对模型求平均的一个简单的近似是使用最可能的一个模型做预测。这被称为模型选择(model selection)。

对于一个由参数$\boldsymbol{w}$控制的模型，根据概率的加和规则和乘积规则，模型证据为
\begin{equation}
	p(D|M_i)=\int p(D|\boldsymbol{w},M_i)p(\boldsymbol{w}|M_i)d\boldsymbol{w}
\end{equation}
从取样的角度来看，边缘似然函数可以被看成从一个模型中生成数据集D的概率，这个模型的参数是从先验分布中随机取样的。同时，注意到模型证据恰好就是在估计参数的后验分布时出现在贝叶斯定理的分母中的归一化项，因为 
\begin{equation}
	p(\boldsymbol{w}|D,M_i)=\frac{p(D|\boldsymbol{w},M_i)p(\boldsymbol{w}|M_i)}{p(D|M_i)}
\end{equation}
通过对参数的积分进行一个简单的近似。我们可以更加深刻地认识模型证据。首先考虑模型有一个参数$w$的情形，这个参数的后验概率正比于$p(D|w)p(w)$，其中，为了简化记号，我们省略了它对于模型$M_i$的依赖。如果假设后验分布在最大似然值$w_{MAP}$附近是一个尖峰，宽度为$\triangle w_{\text{后验}}$，那么可以用被积函数的值乘以尖峰的宽度来近似这个积分。进一步假设先验分布是平的，宽度为$\triangle w_{\text{先验}}$，即$p(w)=\frac{1}{\triangle w_{\text{先验}}}$，那么我们有
\begin{equation}
	p(D)=\int p(D|w)p(w)dw\simeq p(D|w_{MAP})\frac{\triangle w_{\text{后验}}}{\triangle w_{\text{先验}}}
\end{equation}
取对数可得
\begin{equation}
	\ln p(D)\simeq \ln p(D|w_{MAP})+\ln \left(\frac{\triangle w_{\text{后验}}}{\triangle w_{\text{先验}}} \right)
\end{equation}
第一项表示拟合由最可能参数给出的数据。对于平的先验分布来说，这对应于对数似然。第二项用于根据模型的复杂度来惩罚模型。由于$\triangle w_{\text{后验}}<\triangle w_{\text{先验}}$，因此这一项为负，并且随着$\frac{\triangle w_{\text{后验}}}{\triangle w_{\text{先验}}}$的减小，它的绝对值会增加。因此，如果参数精确地调整为后验分布的数据，那么惩罚项会很大。

对于一个有M个参数的模型，我们可以对每个参数进行类似的近似。假设所有的参数的$\frac{\triangle w_{\text{后验}}}{\triangle w_{\text{先验}}}$都相同，我们有
\begin{equation}
\ln p(D)\simeq \ln p(D|w_{MAP})+M\ln \left(\frac{\triangle w_{\text{后验}}}{\triangle w_{\text{先验}}} \right)
\end{equation}
因此，在这种非常简单的近似下，复杂度惩罚项的大小随着模型中可调节参数M的数量线性增加。随着我们增加模型的复杂度，第一项通常会增大，因为一个更加复杂的模型能够更好地拟合数据，而第二项会减小，因为它依赖于M。由最大模型证据确定的最优的模型复杂度需要在这两个相互竞争的项之间进行折中。

本质上说，简单的模型不能很好地拟合数据，而复杂的模型把它的预测概率散布于过多的可能的数据集当中，从而对它们当中的每一个赋予的概率相对较小。由于概率分布是$p(D|M_i)$归一化的，因此我们看到特定的数据集$D_0$对中等复杂度的模型有最高的模型证据。

\textbf{这里补充一个图}

贝叶斯模型比较框架中隐含的一个假设是，生成数据的真实的概率分布包含在考虑的模型集合当中。如果这个假设确实成立，那么我们可以证明，平均来看，贝叶斯模型比较会倾向于选择出正确的模型。为了证明这一点，考虑两个模型$M_1,M_2$。其中真实的概率分布对应于模型$M_1$。对于给定的有限的数据集，确实有可能出现错误的模型反而使贝叶斯因子较大的事情。但是，如果我们把贝叶斯因子在数据集分布上进行平均，那么我们可以得到期望贝叶斯因子 
\begin{equation}
	\int p(D|M_1)\ln \frac{p(D|M_1)}{p(D|M_2)}\mathrm{d}D
\end{equation}
上式是关于数据的真实分布求的平均值。这是Kullback-Leibler散度的一个例子，满足下面的性质：如果两个分布相等，则Kullback-Leibler散等于零，否则恒为正。因此平均来讲，贝叶斯因子总会倾向于选择正确的模型。

我们已经看到，贝叶斯框架避免了过拟合的问题，并且使得模型能够基于训练数据自身进行对比。但是，与模式识别中任何其他的方法一样，贝叶斯方法需要对模型的形式作出假设，并且如果这些假设不合理，那么结果就会出错。特别地，模型证据对先验分布的很多方面都很敏感，例如在低概率处的行为等等。

因此，在实际应用中，一种明智的做法是，保留一个独立的测试数据集，这个数据集用来评估最终系统的整体表现。