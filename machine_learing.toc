\contentsline {chapter}{\numberline {1}深度前馈网络}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}实例：学习XOR}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}基于梯度的学习}{1}{section.1.2}
\contentsline {section}{\numberline {1.3}隐藏单元}{1}{section.1.3}
\contentsline {section}{\numberline {1.4}架构设计}{1}{section.1.4}
\contentsline {section}{\numberline {1.5}反向传播和其他的微分算法}{1}{section.1.5}
\contentsline {chapter}{\numberline {2}深度学习中的正则化}{2}{chapter.2}
\contentsline {section}{\numberline {2.1}参数范数惩罚}{2}{section.2.1}
\contentsline {section}{\numberline {2.2}作为约束的范数惩罚}{2}{section.2.2}
\contentsline {section}{\numberline {2.3}正则化和欠约束问题}{2}{section.2.3}
\contentsline {section}{\numberline {2.4}数据集增强}{2}{section.2.4}
\contentsline {section}{\numberline {2.5}噪声鲁棒性}{2}{section.2.5}
\contentsline {section}{\numberline {2.6}半监督学习}{2}{section.2.6}
\contentsline {section}{\numberline {2.7}多任务学习}{2}{section.2.7}
\contentsline {section}{\numberline {2.8}提前终止}{2}{section.2.8}
\contentsline {section}{\numberline {2.9}参数绑定和参数共享}{2}{section.2.9}
\contentsline {section}{\numberline {2.10}稀疏表示}{2}{section.2.10}
\contentsline {section}{\numberline {2.11}Bagging和其他集成方法}{2}{section.2.11}
\contentsline {section}{\numberline {2.12}Dropout}{2}{section.2.12}
\contentsline {section}{\numberline {2.13}切面距离、正切传播和流形正切分类器}{2}{section.2.13}
\contentsline {chapter}{\numberline {3}深度模型中的优化}{3}{chapter.3}
\contentsline {section}{\numberline {3.1}学习和纯优化有什么不同}{3}{section.3.1}
\contentsline {section}{\numberline {3.2}神经网络优化中的挑战}{3}{section.3.2}
\contentsline {section}{\numberline {3.3}基本算法}{3}{section.3.3}
\contentsline {section}{\numberline {3.4}参数初始化策略}{3}{section.3.4}
\contentsline {section}{\numberline {3.5}自适应学习率算法}{3}{section.3.5}
\contentsline {section}{\numberline {3.6}二阶近似方法}{3}{section.3.6}
\contentsline {section}{\numberline {3.7}优化策略和元算法}{3}{section.3.7}
\contentsline {chapter}{\numberline {4}卷积网络}{4}{chapter.4}
\contentsline {section}{\numberline {4.1}卷积运算}{4}{section.4.1}
\contentsline {section}{\numberline {4.2}动机}{4}{section.4.2}
\contentsline {section}{\numberline {4.3}池化}{4}{section.4.3}
\contentsline {section}{\numberline {4.4}卷积与池化作为一种无限强的先验}{4}{section.4.4}
\contentsline {section}{\numberline {4.5}基本卷积函数的变体}{4}{section.4.5}
\contentsline {section}{\numberline {4.6}结构化输出}{4}{section.4.6}
\contentsline {section}{\numberline {4.7}数据类型}{4}{section.4.7}
\contentsline {section}{\numberline {4.8}高效的卷积算法}{4}{section.4.8}
\contentsline {section}{\numberline {4.9}随机或无监督的特征}{4}{section.4.9}
\contentsline {section}{\numberline {4.10}卷积网络的神经科学基础}{4}{section.4.10}
\contentsline {section}{\numberline {4.11}卷积网络与深度学习的历史}{4}{section.4.11}
\contentsline {chapter}{\numberline {5}序列建模：循环和递归网络}{5}{chapter.5}
\contentsline {section}{\numberline {5.1}展开计算图}{5}{section.5.1}
\contentsline {section}{\numberline {5.2}循环神经网络}{5}{section.5.2}
\contentsline {section}{\numberline {5.3}双向RNN}{5}{section.5.3}
\contentsline {section}{\numberline {5.4}基于编码-解码的序列到序列架构}{5}{section.5.4}
\contentsline {section}{\numberline {5.5}深度循环网络}{5}{section.5.5}
\contentsline {section}{\numberline {5.6}递归神经网络}{5}{section.5.6}
\contentsline {section}{\numberline {5.7}长期依赖的挑战}{5}{section.5.7}
\contentsline {section}{\numberline {5.8}回声状态网络}{5}{section.5.8}
\contentsline {section}{\numberline {5.9}渗漏单元和其他多时间尺度的策略}{5}{section.5.9}
\contentsline {section}{\numberline {5.10}长短期记忆和其他门控RNN}{5}{section.5.10}
\contentsline {section}{\numberline {5.11}优化长期依赖}{5}{section.5.11}
\contentsline {section}{\numberline {5.12}外显记忆}{5}{section.5.12}
\contentsline {chapter}{\numberline {6}实践方法论}{6}{chapter.6}
\contentsline {section}{\numberline {6.1}性能度量}{6}{section.6.1}
\contentsline {section}{\numberline {6.2}默认的基准模型}{6}{section.6.2}
\contentsline {section}{\numberline {6.3}决定是否收集更多数据}{6}{section.6.3}
\contentsline {section}{\numberline {6.4}选择超参数}{6}{section.6.4}
\contentsline {section}{\numberline {6.5}调试策略}{6}{section.6.5}
\contentsline {section}{\numberline {6.6}示例：多位数字识别}{6}{section.6.6}
\contentsline {chapter}{\numberline {7}应用}{7}{chapter.7}
\contentsline {section}{\numberline {7.1}大规模深度学习}{7}{section.7.1}
\contentsline {section}{\numberline {7.2}计算机视觉}{7}{section.7.2}
\contentsline {section}{\numberline {7.3}语音识别}{7}{section.7.3}
\contentsline {section}{\numberline {7.4}自然语言处理}{7}{section.7.4}
\contentsline {section}{\numberline {7.5}其他应用}{7}{section.7.5}
\contentsline {chapter}{\numberline {8}线性因子模型}{8}{chapter.8}
\contentsline {section}{\numberline {8.1}概率PCA和因子分析}{8}{section.8.1}
\contentsline {section}{\numberline {8.2}独立成分分析}{8}{section.8.2}
\contentsline {section}{\numberline {8.3}慢特征分析}{8}{section.8.3}
\contentsline {section}{\numberline {8.4}稀疏编码}{8}{section.8.4}
\contentsline {section}{\numberline {8.5}PCA的流形解释}{8}{section.8.5}
\contentsline {chapter}{\numberline {9}自编码器}{9}{chapter.9}
\contentsline {section}{\numberline {9.1}欠完备自编码器}{9}{section.9.1}
\contentsline {section}{\numberline {9.2}正则自编码器}{9}{section.9.2}
\contentsline {section}{\numberline {9.3}表示能力、层的大小和深度}{9}{section.9.3}
\contentsline {section}{\numberline {9.4}随机编码器和解码器}{9}{section.9.4}
\contentsline {section}{\numberline {9.5}去噪自编码器详解}{9}{section.9.5}
\contentsline {section}{\numberline {9.6}使用自编码器学习流形}{9}{section.9.6}
\contentsline {section}{\numberline {9.7}收缩自编码器}{9}{section.9.7}
\contentsline {section}{\numberline {9.8}预测稀疏分解}{9}{section.9.8}
\contentsline {section}{\numberline {9.9}自编译器的应用}{9}{section.9.9}
\contentsline {chapter}{\numberline {10}表示学习}{10}{chapter.10}
\contentsline {section}{\numberline {10.1}贪心逐层无监督预训练}{10}{section.10.1}
\contentsline {section}{\numberline {10.2}迁移学习和领域自适应}{10}{section.10.2}
\contentsline {section}{\numberline {10.3}半监督解释因果关系}{10}{section.10.3}
\contentsline {section}{\numberline {10.4}分布式表示}{10}{section.10.4}
\contentsline {section}{\numberline {10.5}得益于深度的指数增益}{10}{section.10.5}
\contentsline {section}{\numberline {10.6}提供发现潜在原因的线索}{10}{section.10.6}
\contentsline {chapter}{\numberline {11}深度学习中的结构化概率模型}{11}{chapter.11}
\contentsline {section}{\numberline {11.1}非结构化建模的挑战}{11}{section.11.1}
\contentsline {section}{\numberline {11.2}使用图描述模型结构}{11}{section.11.2}
\contentsline {section}{\numberline {11.3}从图模型中采样}{11}{section.11.3}
\contentsline {section}{\numberline {11.4}结构化建模的优势}{11}{section.11.4}
\contentsline {section}{\numberline {11.5}学习依赖关系}{11}{section.11.5}
\contentsline {section}{\numberline {11.6}推断和近似推断}{11}{section.11.6}
\contentsline {section}{\numberline {11.7}结构化概率模型的深度学习方法}{11}{section.11.7}
\contentsline {chapter}{\numberline {12}深度生成模型}{12}{chapter.12}
\contentsline {section}{\numberline {12.1}玻尔兹曼机}{12}{section.12.1}
\contentsline {section}{\numberline {12.2}受限玻尔兹曼机}{12}{section.12.2}
\contentsline {section}{\numberline {12.3}深度信念网络}{12}{section.12.3}
\contentsline {section}{\numberline {12.4}深度玻尔兹曼机}{12}{section.12.4}
\contentsline {section}{\numberline {12.5}实值数据上的玻尔兹曼机}{12}{section.12.5}
\contentsline {section}{\numberline {12.6}卷积玻尔兹曼机}{12}{section.12.6}
\contentsline {section}{\numberline {12.7}用于结构化或序列输出的玻尔兹曼机}{12}{section.12.7}
\contentsline {section}{\numberline {12.8}其他玻尔兹曼机}{12}{section.12.8}
\contentsline {section}{\numberline {12.9}通过随机操作的反向传播}{12}{section.12.9}
\contentsline {section}{\numberline {12.10}有向生成网络}{12}{section.12.10}
\contentsline {section}{\numberline {12.11}从自编码器采样}{12}{section.12.11}
\contentsline {section}{\numberline {12.12}生成随机网络}{12}{section.12.12}
\contentsline {section}{\numberline {12.13}其他生成方案}{12}{section.12.13}
\contentsline {section}{\numberline {12.14}评估生成模型}{12}{section.12.14}
\contentsline {section}{\numberline {12.15}结论}{12}{section.12.15}
